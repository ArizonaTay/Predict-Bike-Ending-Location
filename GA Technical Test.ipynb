{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8d9b6e",
   "metadata": {},
   "source": [
    "# Table of Content \n",
    "\n",
    "1. Context\n",
    "2. Data Loading\n",
    "3. Data Cleaning\n",
    "    1. Merge Trips & Start Station Information\n",
    "    2. Merge Trips & Weather\n",
    "    3. Remove Duplicates Value\n",
    "    4. Drop Irrelevant columns\n",
    "    5. Identify Missing Values\n",
    "    6. Identify Missing Values\n",
    "    7. Handle incorrect data and data types\n",
    "    8. Handle outliers\n",
    "4. Feature Enginnering\n",
    "    1. Mean Euclidean Distance From Other stations \n",
    "    2. Zipcode Feature Extraction\n",
    "    3. Age Binning\n",
    "    4. Date and Time Feature Extraction and Encoding\n",
    "5. Train Test Validation Split\n",
    "6. Feature Scaling & Feature Encoding\n",
    "7. Oversampling to Balance Class Imbalance\n",
    "8. Model Building\n",
    "    1. Random Forest\n",
    "    2. Gradient Boost\n",
    "    3. SVM\n",
    "9. Conclusion\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd5fce3b",
   "metadata": {},
   "source": [
    "## 1. Context\n",
    "Wheelie Wonka is a bike sharing company in Boston that aims to enhance the mobile app experience for its users. The company wants to show bike availability in the future to its users to help them plan their trips effectively. To achieve this, they need to predict the ending bike station at the beginning of a bike trip.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08baf5d1",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "39a81f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from uszipcode import SearchEngine\n",
    "from scipy.spatial.distance import cdist\n",
    "import math\n",
    "from scipy.stats import skew\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set display options\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.float_format', str)\n",
    "\n",
    "# Load the datasets\n",
    "stations = pd.read_csv(\"hubway_stations.csv\") # load the stations dataset\n",
    "trips = pd.read_csv(\"hubway_trips.csv\") # load the trips dataset\n",
    "weather = pd.read_csv(\"weather.csv\") # load the weather dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ebf8c",
   "metadata": {},
   "source": [
    "## 3 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2906f",
   "metadata": {},
   "source": [
    "#### 3a Merge Start Station Information into Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8456641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the 'stations' dataframe with column prefixes to avoid column name conflicts when merging\n",
    "start_statn_info = stations.copy().add_prefix('strt_statn_')\n",
    "\n",
    "# Merge the 'trips' dataframe with the new 'start_statn_info' dataframe using the 'strt_statn' and 'strt_statn_id' columns as keys\n",
    "trips_station = pd.merge(trips, start_statn_info, how='left', left_on='strt_statn', right_on='strt_statn_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57660c",
   "metadata": {},
   "source": [
    "#### 3b Merge Weathers Information into Trips\n",
    "\n",
    "- <font color='red'>The following columns will be excluded from the weather dataset since they contain only a single value: Station, Station_Name, Elevation, Latitude, Longitude, and Quality_Flag. The 'Measurement_Flag' column is also unlikely to be useful in predicting the trip ending station because we will be extrapolating to fill in missing data. Additionally, whether a measurement was taken by a human or a machine is irrelevant in this context. Therefore, we will also exclude the 'Measurement_Flag' column from the weather dataset. </font>\n",
    "    \n",
    "- <font color='red'>Thus we will only use use the HPCP column</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6921ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the relevant columns from the weather dataset\n",
    "weather_subset = weather[['DATE', 'HPCP']].copy()\n",
    "\n",
    "# Convert the date columns in trips_merged and weather_subset into datetime format.\n",
    "trips_station['start_date'] = pd.to_datetime(trips_station['start_date']).copy()\n",
    "weather_subset['DATE'] = pd.to_datetime(weather_subset['DATE'], format='%Y%m%d %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138cde67",
   "metadata": {},
   "source": [
    "- <font color='red'>The weather data is an important factor in predicting the bike trip ending stations as it can indicate whether the weather conditions are favorable for biking or not. Additionally, weather data is readily available online and can be used as input for our machine learning model. Therefore, it is necessary to deal with the missing datetime values in the weather dataset rather than dropping the entire dataset.</font>\n",
    "\n",
    "\n",
    "- <font color='red'>Despite the significant amount of missing HPCP data, we can still estimate the missing precipitation value by extrapolating the available weather data, as is commonly done in weather forecasting services. Although extrapolation may introduce some uncertainty into the estimates, it can still provide valuable information for our machine learning model.</font>\n",
    "\n",
    "\n",
    "- <font color='red'>There are several methods for dealing with missing data, including forward fill, backward fill, mean and median imputation, and interpolation. In my analysis, I chose to use interpolation because it is more effective when dealing with a large amount of missing data. Additionally, since weather data typically exhibit gradual changes or trends, interpolation is better able to detect subtle variations.</font>\n",
    "\n",
    "\n",
    "- <font color='red'>I decided to use cubic interpolation instead of linear interpolation because it is more accurate when interpolating highly curved or noisy data. This will help us obtain more precise estimates of the missing precipitation values, which will be useful in our machine learning model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14dcd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of the weather_subset dataframe to the 'DATE' column\n",
    "weather_subset = weather_subset.set_index('DATE')\n",
    "\n",
    "# Resample the weather data to hourly intervals\n",
    "weather_subset_resampled = weather_subset.resample('H').asfreq()\n",
    "\n",
    "# Interpolate the missing values using cubic interpolation\n",
    "weather_subset_resampled_interpolated = weather_subset_resampled.interpolate(method='cubic')\n",
    "\n",
    "# Reset the index to convert the 'DATE' column back to a regular column\n",
    "weather_subset_resampled_interpolated = weather_subset_resampled_interpolated.reset_index()\n",
    "\n",
    "# Sort the trips_station dataframe by 'start_date'\n",
    "trips_station_weather = trips_station.sort_values('start_date')\n",
    "\n",
    "# Merge the trips_station dataframe with the weather data using the nearest available value\n",
    "trips_station_weather = pd.merge_asof(trips_station_weather, weather_subset_resampled_interpolated, direction='nearest', left_on='start_date', right_on = 'DATE')\n",
    "\n",
    "# Keep only the rows where the difference between 'DATE' and 'start_date' is less than or equal to one hour\n",
    "trips_station_weather = trips_station_weather[( abs(trips_station_weather['DATE'] - trips_station_weather['start_date']).dt.total_seconds()) <= 3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b755925f",
   "metadata": {},
   "source": [
    "#### 3c Remove Duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277c4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate values\n",
    "trips_station_weather = trips_station_weather.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b177901",
   "metadata": {},
   "source": [
    "#### 3d Drop Irrelevant columns\n",
    "\n",
    "<font color='red'>To prepare our dataset for machine learning, we need to remove columns that are not relevant to our prediction task. Therefore, we will drop the following columns:</font>\n",
    "\n",
    "- status: This column is not relevant to our prediction task.\n",
    "- end_date: We cannot use this information for prediction as it is only available after the trip has ended.\n",
    "- duration: Similarly, we cannot use this information as it would only be available after the trip has ended.\n",
    "\n",
    "\n",
    "<font color='red'>Additionally, we will remove the following IDs:</font>\n",
    "- seq_id:  The seq ID is not relevant to our prediction task.\n",
    "- hubway_id:  The seq ID is not relevant to our prediction task.\n",
    "- bike_nr: The bike ID is not relevant to our prediction task.\n",
    "- strt_statn_terminal: The Terminal id is not relevant to our prediction task.\n",
    "- strt_statn_station: The Station Name is not relevant to our prediction task as we already have the latitude and longitude of the station.\n",
    "- strt_statn_status: The station status is not relevant to our prediction task since they only contain 1 value.\n",
    "- DATE: The DATE is not relevant to our prediction task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34da967",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['seq_id', 'hubway_id', 'status', 'bike_nr', 'end_date', \n",
    "               'strt_statn_terminal', 'strt_statn_station','strt_statn_status', 'strt_statn_id',\n",
    "               'duration', 'DATE']\n",
    "trips_station_weather = trips_station_weather.drop(columns = col_to_drop).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63628274",
   "metadata": {},
   "source": [
    "#### 3e Identify Missing Values\n",
    "\n",
    "- <font color='red'>Since the strt_statn_lat and strt_statn_lng are essential features for our analysis and predictions, the trips without these values will not contribute to our model. Therefore, it is reasonable to drop the corresponding rows from the dataset. Luckily, the number of missing rows is insignificant, with only 14 and 45 out of 1,042,677 trips, respectively.</font>\n",
    "\n",
    "\n",
    "- <font color='red'>To avoid data loss, I will replace the missing values of the zip_code, birth_date, and gender columns with a custom value that represents missing data. More will be done during data enginnering</font>\n",
    "    \n",
    "        For the 'gender' column, I will replace any missing values with the string \"Missing\" to indicate that the data is not Missing.\n",
    "\n",
    "        For the 'birth_date' column, I will create a new category called \"Missing\" and group all the rows with missing birth dates into this category. The other age will be bin into a age group.\n",
    "\n",
    "        For the 'zip_code' column, I will use the available data to generate the corresponding latitude and longitude values, which are more relevant for our analysis. Since there is no good way to interpolate the missing data, I will replace the missing zip codes with either median/mean value based on the skewness of the data to minimize the impact on the latitude and longitude calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75025ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Missing Values:\n",
      " start_date                   0\n",
      "strt_statn                  14\n",
      "end_statn                   45\n",
      "subsc_type                   0\n",
      "zip_code                339102\n",
      "birth_date              692282\n",
      "gender                  339036\n",
      "strt_statn_municipal        14\n",
      "strt_statn_lat              14\n",
      "strt_statn_lng              14\n",
      "HPCP                         0\n",
      "dtype: int64\n",
      "\n",
      "Non-Standard Missing Values:\n",
      " start_date              0\n",
      "strt_statn              0\n",
      "end_statn               0\n",
      "subsc_type              0\n",
      "zip_code                0\n",
      "birth_date              0\n",
      "gender                  0\n",
      "strt_statn_municipal    0\n",
      "strt_statn_lat          0\n",
      "strt_statn_lng          0\n",
      "HPCP                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_standard = trips_station_weather.isna().sum()\n",
    "missing_nonstandard = trips_station_weather.isin(['n/a', 'NA', ' ', 'nan']).sum()\n",
    "\n",
    "# Print the number of missing values for each column\n",
    "print('Standard Missing Values:\\n', missing_standard)\n",
    "print('\\nNon-Standard Missing Values:\\n', missing_nonstandard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6470d376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_date              0\n",
       "strt_statn              0\n",
       "end_statn               0\n",
       "subsc_type              0\n",
       "zip_code                0\n",
       "birth_date              0\n",
       "gender                  0\n",
       "strt_statn_municipal    0\n",
       "strt_statn_lat          0\n",
       "strt_statn_lng          0\n",
       "HPCP                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Missing Values from strt_statn, end_statn and bike_nr\n",
    "trips_station_weather.dropna(subset=['strt_statn_lat', 'end_statn'], inplace=True)\n",
    "\n",
    "#Populate Missing Values in Gender Zipcode and birth_date\n",
    "for i in ['gender', 'zip_code', 'birth_date']:\n",
    "    trips_station_weather[i] = trips_station_weather[i].fillna('Missing')\n",
    "\n",
    "# Verify that there are no more missing values\n",
    "trips_station_weather.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a9814",
   "metadata": {},
   "source": [
    "#### 3f Handling incorrect data and data types\n",
    "\n",
    "- Remove apostrophe from zip code\n",
    "- Filter out unrealistic birth dates <15 or >100\n",
    "- Filter out unrealistic Lat and Lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76574b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_station_weather['zip_code'] = trips_station_weather['zip_code'].str.lstrip(\"'\")\n",
    "\n",
    "# Calculate age from birth_date and start_date\n",
    "trips_station_weather['age'] = (trips_station_weather['start_date'] - pd.to_datetime(trips_station_weather['birth_date'],format='%Y.0',errors='coerce')).astype('<m8[Y]')\n",
    "\n",
    "#Remove all age below 15 or above 100\n",
    "valid_age = ((trips_station_weather['age'] >= 15) & (trips_station_weather['age'] <= 100)) | trips_station_weather['age'].isna() \n",
    "trips_station_weather = trips_station_weather[valid_age]\n",
    "\n",
    "trips_station_weather = trips_station_weather[(trips_station_weather['strt_statn_lat'] >= -90) & \n",
    "                                              (trips_station_weather['strt_statn_lat'] <= 90)]\n",
    "\n",
    "# Remove rows with impossible longitude values\n",
    "trips_station_weather = trips_station_weather[(trips_station_weather['strt_statn_lng'] >= -180) & \n",
    "                                              (trips_station_weather['strt_statn_lng'] <= 180)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657b2d5",
   "metadata": {},
   "source": [
    "#### 3g Handle outliers\n",
    "\n",
    "- To identify the outliers in our data, we calculate the z-score for the HPCP column using the zscore() method from the scipy.stats module.\n",
    "\n",
    "- From the below code, we found several data points with HPCP values greater than 3 standard deviations from the mean. Since we want to retain the impact of extreme weather conditions on bike usage, we decided to keep these outliers and not remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ac1fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3836,   3837,   3838, ..., 832270, 832271, 832272], dtype=int64),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "trips_station_weather.describe()\n",
    "\n",
    "#Calculate z-score for HPCP\n",
    "plt.hist(X_test[['HPCP']])\n",
    "z = np.abs(stats.zscore(trips_station_weather['HPCP']))\n",
    "\n",
    "#Identify HPCP outliers with a z-score greater than 3 or less than -3\n",
    "hpcp_arr_outliers = np.where(z > 3)\n",
    "hpcp_arr_outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b199c",
   "metadata": {},
   "source": [
    "## 4 Feature Enginnering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b66851",
   "metadata": {},
   "source": [
    "#### 4a Mean Euclidean distance from all other stations \n",
    "\n",
    "- Enginnering the mean Euclidean distance between each bike station and all other stations in the dataset. This is important because it can give us a sense of how well-connected each station is to the rest of the network, which might affect ridership patterns or the feasibility of certain trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69ad7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean Euclidean distance between each station and all others\n",
    "\n",
    "# create a dataframe with unique station IDs and their respective latitude and longitude coordinates\n",
    "station_coords_df = trips_station_weather[['strt_statn', 'strt_statn_lat', 'strt_statn_lng']].drop_duplicates(subset='strt_statn').reset_index(drop=True)\n",
    "\n",
    "# define a function to convert latitude and longitude to Cartesian coordinates\n",
    "def get_cartesian_coords(latitude, longitude, elevation=0):\n",
    "    # convert latitude and longitude to radians\n",
    "    latitude = np.radians(latitude)\n",
    "    longitude = np.radians(longitude)\n",
    "\n",
    "    # radius of Earth in kilometers\n",
    "    R = 6371  \n",
    "\n",
    "    # calculate Cartesian coordinates using the formula for a sphere\n",
    "    x = (R + elevation) * np.cos(latitude) * np.cos(longitude)\n",
    "    y = (R + elevation) * np.cos(latitude) * np.sin(longitude)\n",
    "    z = (R + elevation) * np.sin(latitude)\n",
    "\n",
    "    return (x, y, z)\n",
    "\n",
    "# apply the get_cartesian_coords function to each row of the station_coords_df dataframe to convert latitude and longitude coordinates to Cartesian coordinates\n",
    "cartesian_coords = np.stack(station_coords_df.apply(lambda row: get_cartesian_coords(row['strt_statn_lat'], row['strt_statn_lng']), axis=1))\n",
    "\n",
    "# calculate the Euclidean distance between each pair of stations using their Cartesian coordinates\n",
    "distances = cdist(cartesian_coords, cartesian_coords, metric='euclidean')\n",
    "\n",
    "# calculate the mean distance between each station and all other stations by taking the mean of the distances across the rows of the distances array\n",
    "mean_distances = distances.mean(axis=1)\n",
    "\n",
    "# create a new dataframe to store the station IDs and their respective mean distances\n",
    "station_distances_df = pd.DataFrame({'strt_statn': station_coords_df['strt_statn'], 'mean_euclidean_dist': mean_distances})\n",
    "\n",
    "# merge the station_distances_df dataframe with the original trips_station_weather dataframe\n",
    "# using the 'strt_statn' column to add the mean distance between each station and all other stations to the trips_station_weather dataframe\n",
    "trips_station_weather = trips_station_weather.merge(station_distances_df, on='strt_statn', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b73fdb",
   "metadata": {},
   "source": [
    "#### 4b Zipcode Feature Extraction\n",
    "- Latitudes and longitudes are more useful than zip codes as they provide a more accurate representation of location than zip codes.\n",
    "\n",
    "- Better distance calculations: Distance calculations are more accurate when using latitudes and longitudes. This is important for machine learning models that rely on distance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e43103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness Lat: -30.553020603660276\n",
      "Skewness Lng: -31.48186777513227\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract the latitude and longitude coordinates of a given zip code\n",
    "def store_zip_code_into_dict(zipcode):\n",
    "    result = search.by_zipcode(zipcode)\n",
    "    if result is None:\n",
    "        return 'Missing', 'Missing'  # If the zip code is not found, return placeholders\n",
    "    else:\n",
    "        res = result.to_dict()\n",
    "        return res['lat'], res['lng'],  # Return the latitude and longitude values from the search result\n",
    "    \n",
    "# Define a function to retrieve the latitude and longitude values for a given zip code from the pre-stored dictionary\n",
    "def get_lat_long(zip_code):\n",
    "    return zip_code_dict[zip_code]\n",
    "\n",
    "# Instantiate a search engine to search for zip codes and create an empty dictionary to store the results\n",
    "search = SearchEngine() \n",
    "zip_code_dict = {}\n",
    "\n",
    "# Loop through each unique zip code in the trips_station_weather_feature_eng dataframe\n",
    "for i in trips_station_weather['zip_code'].unique().tolist():\n",
    "    zip_code_dict[i] = store_zip_code_into_dict(i)  # Store the latitude and longitude values for each zip code in the dictionary\n",
    "\n",
    "# Apply the get_zip_info function to the zip_code column of the trips_station_weather dataframe to extract latitude and longitude values\n",
    "trips_station_weather[['home_lat', 'home_lng']] = trips_station_weather['zip_code'].apply(get_lat_long).apply(pd.Series)\n",
    "\n",
    "# calculate skewness of a Lat & Lng\n",
    "lat_skewness = skew(trips_station_weather[trips_station_weather['home_lat'] != 'Missing']['home_lat'])\n",
    "lng_skewness = skew(trips_station_weather[trips_station_weather['home_lng'] != 'Missing']['home_lng'])\n",
    "print('Skewness Lat:', lat_skewness)\n",
    "print('Skewness Lng:', lng_skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccc4ed",
   "metadata": {},
   "source": [
    "- To fill in the missing values for the latitude and longitude coordinates, we could use various techniques such as interpolation, regression, or clustering. However, since the data is heavily skewed, meaning that the distribution is not normal, it is difficult to apply these methods to fill in the missing values accurately. \n",
    "\n",
    "\n",
    "- Therefore, the most appropriate method in this case is to use the median value of the available data to replace the missing values, which can provide a more robust estimate of the missing values compared to using the mean or other statistical measures. This is a common technique in data cleaning and preprocessing when dealing with skewed data, as it provides a more reliable estimate of the central tendency of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2871263",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['home_lng', 'home_lat']:\n",
    "    trips_station_weather.loc[trips_station_weather[i] == 'Missing', i] = trips_station_weather[trips_station_weather[i] != 'Missing'][i].mean()\n",
    "    trips_station_weather[i] = trips_station_weather[i].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e3275",
   "metadata": {},
   "source": [
    "#### 4c Age Binning\n",
    "\n",
    "- Given the large number of missing values in the birth_date column, I opted to bin the age variable so i can create a column to indicate the missing value. As customers who do not input their birth date may share a common characteristic, it would not be prudent to simply remove them. To determine appropriate bin sizes, I utilized a histogram to visualize the distribution of ages, and noticed distinct cutoff points at 25, 30, 35, 40, and 55. Consequently, I created age bins below Missing, 16-25, between 26-30, between 31-35, 36-55and above 55 to segment the age group into meaningful categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f10b6336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 33164., 100643.,  73845.,  46394.,  36149.,  34772.,  17730.,\n",
       "          6669.,    887.,    113.]),\n",
       " array([17. , 23.2, 29.4, 35.6, 41.8, 48. , 54.2, 60.4, 66.6, 72.8, 79. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trips_station_weather['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15e4c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels for age groups\n",
    "bins = [-1, 16, 25, 35, 40, 55, 100]\n",
    "labels = ['Missing', '16-25', '26-30', '31-35', '36-55', '56+']\n",
    "\n",
    "# Bin the age column based on bike usage\n",
    "trips_station_weather['age'] = trips_station_weather['age'].fillna(0)\n",
    "trips_station_weather['age_group'] = pd.cut(trips_station_weather['age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8c215",
   "metadata": {},
   "source": [
    "#### 4d Date and Time Feature Extraction and Encoding\n",
    "\n",
    "- The code block mentioned here contains a set of functions that aim to extract various relevant date and time features from a datetime column and encode them in a cyclical manner. This approach is particularly useful in time-series analysis, where the temporal patterns are cyclical in nature.\n",
    "\n",
    "- The features extracted by these functions include day of the week, month, day, hour, week of the year, and additional features such as whether a date falls on a weekend and the time of day. These features are often used as input variables in predictive models that aim to forecast trends or patterns in time-series data.\n",
    "\n",
    "- To encode these features in a cyclical manner, the functions use sine and cosine functions. Sine and cosine functions are periodic, which means they can represent cyclical patterns in time. For instance, the sine function repeats itself every 2π radians or 360 degrees, and the cosine function repeats itself every π/2 radians or 90 degrees.\n",
    "\n",
    "- By using sine and cosine functions to encode the extracted features, the functions represent cyclical patterns in a compact and continuous way. This approach is particularly useful when working with cyclical features such as hours of the day or months of the year, where traditional encoding techniques such as one-hot encoding can result in high-dimensional and sparse feature representations.\n",
    "\n",
    "- Overall, these functions are useful in extracting and encoding relevant time features from a datetime column, allowing for the efficient analysis and modeling of cyclical time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dd903e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_info(dt):\n",
    "    if dt.weekday() in [5, 6]:\n",
    "        weekend = 1  \n",
    "    else:\n",
    "        weekend = 0\n",
    "        \n",
    "    hour = dt.hour\n",
    "    if hour < 6:\n",
    "        time_of_day = 'early morning'\n",
    "    elif hour < 10:\n",
    "        time_of_day = 'rush hour'\n",
    "    elif hour < 16:\n",
    "        time_of_day = 'afternoon'\n",
    "    elif hour < 18:\n",
    "        time_of_day = 'evening'\n",
    "    else:\n",
    "        time_of_day = 'night'\n",
    "\n",
    "    month = dt.month\n",
    "    if month in [12, 1, 2]:\n",
    "        season = 'winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        season = 'spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        season = 'summer'\n",
    "    else:\n",
    "        season = 'fall'\n",
    "    return [weekend, time_of_day, season]\n",
    "\n",
    "def encode_cyclical(row):\n",
    "    hour_sin = np.sin(2 * np.pi * row['start_hour'] / 24)\n",
    "    hour_cos = np.cos(2 * np.pi * row['start_hour'] / 24)\n",
    "    dow_sin = np.sin(2 * np.pi * row['start_day_of_week'] / 7)\n",
    "    dow_cos = np.cos(2 * np.pi * row['start_day_of_week'] / 7)\n",
    "    month_sin = np.sin(2 * np.pi * row['start_month'] / 12)\n",
    "    month_cos = np.cos(2 * np.pi * row['start_month'] / 12)\n",
    "    day_sin = np.sin(2 * np.pi * row['start_day'] / 31)\n",
    "    day_cos = np.cos(2 * np.pi * row['start_day'] / 31)\n",
    "    week_sin = np.sin(2 * np.pi * row['start_week_of_year'] / 52)\n",
    "    week_cos = np.cos(2 * np.pi * row['start_week_of_year'] / 52)\n",
    "    return pd.Series([hour_sin, hour_cos, dow_sin, dow_cos, month_sin, month_cos, week_sin, week_cos, day_sin, day_cos])\n",
    "\n",
    "# Extract day of week, month, day, hour, and week of year from start_date\n",
    "trips_station_weather['start_day_of_week'] = trips_station_weather['start_date'].dt.dayofweek\n",
    "trips_station_weather['start_month'] = trips_station_weather['start_date'].dt.month\n",
    "trips_station_weather['start_day'] = trips_station_weather['start_date'].dt.day\n",
    "trips_station_weather['start_hour'] = trips_station_weather['start_date'].dt.hour\n",
    "trips_station_weather['start_week_of_year'] = trips_station_weather['start_date'].dt.isocalendar().week\n",
    "\n",
    "encoded_trip = trips_station_weather.apply(encode_cyclical, axis=1)\n",
    "encoded_trip.columns = ['hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'month_sin', 'month_cos', 'week_sin', 'week_cos', 'day_sin', 'day_cos']\n",
    "\n",
    "trips_station_weather[['weekend', 'time_of_day','season']] = trips_station_weather['start_date'].apply(extract_date_info).apply(pd.Series)\n",
    "trips_station_weather = pd.concat([trips_station_weather, encoded_trip], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2085e35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'start_hour'}>], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'start_week_of_year'}>], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing the distribution of start hours and start weeks of the year to determine the bins for hours and month.\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "trips_station_weather.hist('start_hour', bins = 24, ax=axes[0])\n",
    "trips_station_weather.hist('start_week_of_year',ax=axes[1], bins = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9a7b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "drop_cols = ['start_date', 'strt_statn', 'age', 'birth_date', 'zip_code']\n",
    "trips_station_weather.drop(columns = drop_cols, inplace = True)\n",
    "\n",
    "#Convert data to correct datatype\n",
    "for i in ['end_statn']:\n",
    "    trips_station_weather[i] = trips_station_weather[i].astype(float)\n",
    "trips_station_weather['start_week_of_year'] = trips_station_weather['start_week_of_year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd10d8f",
   "metadata": {},
   "source": [
    "## 5 Train Test Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2fcef45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trips_station_weather.drop(\"end_statn\", axis = 1)\n",
    "y = trips_station_weather['end_statn']\n",
    "\n",
    "#Split the data into X and y\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8, random_state=40, stratify = y)\n",
    "\n",
    "#Further split the validation set into validation and test sets\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem,test_size=0.5, random_state=40, stratify = y_rem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee265ca",
   "metadata": {},
   "source": [
    "## 6 Feature Scaling & Feature Encoding\n",
    "\n",
    "- Apply Standard Scaler to all numeric columns that do not contain outliers.\n",
    "- Use Robust Scaler to scale the HPCP column.\n",
    "- Perform Ordinal Encoding on the columns with 2 unique values.\n",
    "- For categorical columns with more than two unique values, use One-Hot Encoding to encode the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "48722e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "#numeric_cols = X.select_dtypes(include=['float']).columns.tolist()\n",
    "numeric_cols = ['strt_statn_lat','strt_statn_lng','mean_euclidean_dist','home_lat','home_lng','hour_sin','hour_cos','dow_sin','dow_cos', 'month_sin','month_cos','week_sin','week_cos','day_sin','day_cos']\n",
    "\n",
    "# Fit and transform the training set\n",
    "X_train[numeric_cols]  = scaler.fit_transform(X_train[numeric_cols])\n",
    "\n",
    "# Transform the validation set using the scaler fitted on the training set\n",
    "X_valid[numeric_cols] = scaler.transform(X_valid[numeric_cols])\n",
    "\n",
    "# Transform the test set using the scaler fitted on the training set\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Instantiate the RobustScaler object\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform the training set\n",
    "X_train[['HPCP']] = robust_scaler.fit_transform(X_train[['HPCP']])\n",
    "\n",
    "# Transform the validation set using the scaler fitted on the training set\n",
    "X_valid[['HPCP']] = robust_scaler.transform(X_valid[['HPCP']])\n",
    "\n",
    "# Transform the test set using the scaler fitted on the training set\n",
    "X_test[['HPCP']] = robust_scaler.transform(X_test[['HPCP']])\n",
    "\n",
    "ordinal_cols = ['subsc_type']\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# create an Ordinal encoder for binary features\n",
    "encoded_binary_train = ordinal_encoder.fit_transform(X_train[ordinal_cols])\n",
    "encoded_binary_valid = ordinal_encoder.transform(X_valid[ordinal_cols])\n",
    "encoded_binary_test = ordinal_encoder.transform(X_test[ordinal_cols])\n",
    "\n",
    "# convert encoded features to new DataFrames\n",
    "encoded_binary_train = pd.DataFrame(encoded_binary_train, columns=ordinal_encoder.get_feature_names_out(ordinal_cols))\n",
    "encoded_binary_valid = pd.DataFrame(encoded_binary_valid, columns=ordinal_encoder.get_feature_names_out(ordinal_cols))\n",
    "encoded_binary_test = pd.DataFrame(encoded_binary_test, columns=ordinal_encoder.get_feature_names_out(ordinal_cols))\n",
    "\n",
    "string_cols = (X.select_dtypes(include=['object','category']).columns.tolist())[1:]\n",
    "\n",
    "# create an one-hot encoder for categorical features\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categories_train = onehot_encoder.fit_transform(X_train[string_cols])\n",
    "encoded_categories_valid = onehot_encoder.transform(X_valid[string_cols])\n",
    "encoded_categories_test = onehot_encoder.transform(X_test[string_cols])\n",
    "\n",
    "# convert encoded features to new DataFrames\n",
    "encoded_categories_train = pd.DataFrame(encoded_categories_train, columns=onehot_encoder.get_feature_names_out(string_cols))\n",
    "encoded_categories_valid = pd.DataFrame(encoded_categories_valid, columns=onehot_encoder.get_feature_names_out(string_cols))\n",
    "encoded_categories_test = pd.DataFrame(encoded_categories_test, columns=onehot_encoder.get_feature_names_out(string_cols))\n",
    "\n",
    "\n",
    "X_train_encoded = pd.concat([X_train.reset_index(drop = True), encoded_binary_train,encoded_categories_train], axis=1)\n",
    "X_valid_encoded = pd.concat([X_valid.reset_index(drop = True), encoded_binary_valid,encoded_categories_valid], axis=1)\n",
    "X_test_encoded = pd.concat([X_test.reset_index(drop = True), encoded_binary_test,encoded_categories_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a7e24055",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols.append('subsc_type')\n",
    "string_cols.extend(['start_day_of_week','start_month','start_day','start_hour','start_week_of_year'])\n",
    "X_train_encoded.drop(columns = string_cols, inplace= True)\n",
    "X_valid_encoded.drop(columns = string_cols, inplace= True)\n",
    "X_test_encoded.drop(columns = string_cols, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087464c",
   "metadata": {},
   "source": [
    "## 7. Oversampling to Balance Class Imbalance\n",
    "\n",
    "- I noticed a significant class imbalance in our target class, with some targets having over 40,000 rows and others with as few as 57 rows. To address this issue, I implement oversampling to create a more balanced dataset and improve the model's ability to generalize and make accurate predictions for both majority and minority classes. I choose oversampling over undersampling because oversampling does not discard any data. Also oversampling can also help preserve important patterns and relationships in the data, which may be lost if instances are removed through undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4b5d18bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.0     42426\n",
       "36.0     31792\n",
       "42.0     26805\n",
       "33.0     22923\n",
       "53.0     22590\n",
       "         ...  \n",
       "105.0      234\n",
       "134.0      173\n",
       "144.0      129\n",
       "143.0       70\n",
       "142.0       57\n",
       "Name: end_statn, Length: 125, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify class_imblanace\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_train_encoded_balanced, y_balanced = sm.fit_resample(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e3a2f",
   "metadata": {},
   "source": [
    "## 8. Model Building\n",
    "\n",
    "Due to CPU constraints, I was unable to run grid search or Bayesian optimization on all models. Therefore, I will rely on intuitive hyperparameter settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd248a",
   "metadata": {},
   "source": [
    "#### 8a Random Forest\n",
    "\n",
    "- Given the significant number of distance variables in this multi-class classification problem, I have decided to use the Random Forest algorithm. Random Forest is a suitable choice for this problem because it is capable of handling high-dimensional data and can identify relevant variables while reducing the impact of irrelevant variables. Furthermore, as a tree-based model, it is effective at capturing complex relationships between variables and decision boundaries. Additionally, Random Forest can handle imbalanced datasets and is less prone to overfitting compared to other models such as decision trees. By using Random Forest, I can expect a robust and accurate model that is able to generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b48203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "'''\n",
    "param_grid = {'n_estimators': (10, 1000),\n",
    "            'max_depth': (2, 50),\n",
    "            'min_samples_split': (2, 20),\n",
    "            'max_features': (0.1, 1.0)}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv= 2)\n",
    "grid_search.fit(X_train_val, y_train_val)\n",
    "# Get the best hyperparameters\n",
    "best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "best_max_depth = grid_search.best_params_['max_depth']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1175839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, min_samples_split=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, min_samples_split=3, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15, min_samples_split=3, random_state=42)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the training and validation sets\n",
    "X_train_val = np.concatenate((X_train_encoded, X_valid_encoded))\n",
    "y_train_val = np.concatenate((y_train, y_valid))\n",
    "\n",
    "#Grid Search\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,max_depth = 15, min_samples_split  = 3)\n",
    "rf.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d92d9ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gratz\\anaconda3\\lib\\site-packages\\sklearn\\base.py:402: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Valid Accuracy Score: 0.36385957658131934\n",
      "Train_Valid Precision Score: 0.4401443869062015\n",
      "Train_Valid Recall Score: 0.36385957658131934\n",
      "Train_Valid F1 Score: 0.3624472607933242\n",
      "Test Accuracy Score: 0.2735486222341578\n",
      "Test Precision Score: 0.3245982307552732\n",
      "Test Recall Score: 0.2735486222341578\n",
      "Test F1 Score: 0.26621291666039243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gratz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(y_true, y_pred, prefix):\n",
    "    print(prefix + \" Accuracy Score:\", accuracy_score(y_true, y_pred))\n",
    "    print(prefix + \" Precision Score:\", precision_score(y_true, y_pred, average='weighted'))\n",
    "    print(prefix + \" Recall Score:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "    print(prefix + \" F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "# Make predictions on the validation and test data\n",
    "y_train_val_pred = rf.predict(X_train_val)\n",
    "y_test_pred = rf.predict(X_test_encoded)\n",
    "\n",
    "# Print the metrics for the validation and test data\n",
    "print_metrics(y_train_val, y_train_val_pred, \"Train_Valid\")\n",
    "print_metrics(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192af9cf",
   "metadata": {},
   "source": [
    "#### 8b Gradient Boost\n",
    "- When it comes to predicting bike ending trip context, Gradient Boost is a strong model choice due to its ability to handle a large number of distance features and multi-class classification. The model's ability to capture complex non-linear relationships between the features and target variable can improve predictive accuracy by revealing the underlying structure of the data. This is especially important in predicting bike ending trip context, where there may be complex relationships between variables such as distance, time of day, and weather conditions(HPCP).\n",
    "\n",
    "\n",
    "- Furthermore, Gradient Boost's ability to handle high-dimensional data makes it well-suited for problems with many potential predictors, such as the rider's age or gender. The model's ability to handle a large number of predictors can lead to more accurate predictions and help identify the key factors that contribute to bike ending trip context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=15, learning_rate=0.3, max_depth=2, random_state=42)\n",
    "\n",
    "# fit the classifier to the training data\n",
    "gb.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, prefix):\n",
    "    print(prefix + \" Accuracy Score:\", accuracy_score(y_true, y_pred))\n",
    "    print(prefix + \" Precision Score:\", precision_score(y_true, y_pred, average='weighted'))\n",
    "    print(prefix + \" Recall Score:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "    print(prefix + \" F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "# Make predictions on the validation and test data\n",
    "y_train_val_pred = gb.predict(X_train_val)\n",
    "y_test_pred = gb.predict(X_test_encoded)\n",
    "\n",
    "# Print the metrics for the validation and test data\n",
    "print_metrics(y_train_val, y_train_val_pred, \"Train_Valid\")\n",
    "print_metrics(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06e69e",
   "metadata": {},
   "source": [
    "#### 8c SVM\n",
    "- When it comes to predicting bike end station context, SVM is a highly suitable model due to its ability to effectively handle datasets with many distance variables. In this context, distance variables are likely to play a key role in determining the end station of a bike ride. Additionally, SVM is highly effective at handling non-linearly separable data, which is useful when there are complex relationships between the predictors and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b03645",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=1, gamma='auto')\n",
    "svm.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, prefix):\n",
    "    print(prefix + \" Accuracy Score:\", accuracy_score(y_true, y_pred))\n",
    "    print(prefix + \" Precision Score:\", precision_score(y_true, y_pred, average='weighted'))\n",
    "    print(prefix + \" Recall Score:\", recall_score(y_true, y_pred, average='weighted'))\n",
    "    print(prefix + \" F1 Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "# Make predictions on the validation and test data\n",
    "y_train_val_pred = gb.predict(X_train_val)\n",
    "y_test_pred = gb.predict(X_test_encoded)\n",
    "\n",
    "# Print the metrics for the validation and test data\n",
    "print_metrics(y_train_val, y_train_val_pred, \"Train_Valid\")\n",
    "print_metrics(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ca49c",
   "metadata": {},
   "source": [
    "## 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad46fe",
   "metadata": {},
   "source": [
    "Overall, the result of this project is moderately successful. We achieved an accuracy rate of approximately 30% for a multi-class classification problem with 125 labels, which is a good start but leaves room for improvement. One potential area for improvement is to explore the use of more advanced machine learning models, particularly deep learning models, which are known for their ability to capture complex patterns in data. This may help to further improve the accuracy of the model and potentially uncover new insights into the factors that influence bike usage.\n",
    "\n",
    "Another possible improvement is to gather more detailed information about the users themselves, such as their gender and age. By collecting this information, we can better understand how different demographics use bikes and potentially identify new factors that influence usage. Additionally, we could consider adding more features to the model, such as additional weather conditions or even information about the terrain of the route. This could help to provide a more comprehensive understanding of the factors that influence bike usage and lead to more accurate predictions.\n",
    "\n",
    "In conclusion, while the current model has achieved a moderate level of success, there are several areas where we can improve its performance. By exploring advanced machine learning models, gathering more detailed user information, and incorporating additional features into the model, we can continue to refine our understanding of bike usage and make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526a278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
